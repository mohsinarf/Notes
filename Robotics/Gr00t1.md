# Robotic Architecture Overview

## ğŸ§  System 2: Vision-Language Model (VLM) â€” "The Reasoning Module"
- **Function**: High-level understanding and reasoning based on visual input and language instructions.
- **Hardware**: Runs at **10Hz** on an **NVIDIA L40 GPU** â€” slower but deliberate processing.
- **Inputs**:
  - Visual perception (e.g., camera feeds)
  - Natural language instructions (e.g., â€œPick up the red cupâ€)
- **Model Type**: Pre-trained **Vision-Language Model** (e.g., CLIP, Flamingo)

---

## ğŸ¤– System 1: Diffusion Transformer for Motion Generation â€” "The Action Module"
- **Function**: Real-time motor control and action generation.
- **Speed**: Operates at **120Hz** â€” fast and reactive.
- **Training Method**: Uses **action flow-matching** â€” learns temporal evolution of actions.
- **Architecture**:
  - **Transformer-based**
  - Uses **cross-attention** to interpret VLM outputs
  - Includes **embodiment-specific encoders/decoders** â€” adapts to robot hardware (e.g., joints, grippers)
- **Output**: **Closed-loop motor actions** â€” continuously adjusts using sensor feedback
